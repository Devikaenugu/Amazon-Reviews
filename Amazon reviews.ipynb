{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9d798ff",
   "metadata": {},
   "source": [
    "                                       CAPSTONE PROJECT\n",
    "                                              ON\n",
    "                                 ANALYZE THE CUSTOMER REVIEWS\n",
    "                                              BY   \n",
    "                                          DEVIKA ENUGU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a9e12",
   "metadata": {},
   "source": [
    "# 1 PROBLEM STATEMENT –"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb498226",
   "metadata": {},
   "source": [
    "▪ You are working in an e-commerce company, and your company has put forward a task to analyze the customer reviews for various products. You are supposed to create a report that classifies the products based on the customer reviews.\n",
    "\n",
    "▪ Dataset Information: The Reviews.csv dataset contains 568454 rows and 10 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b370d57c",
   "metadata": {},
   "source": [
    "# 2 PROJECT OBJECTIVE –"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f471e79",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  ▪ Product reviews are a major reason why consumers prefer ecommerce. Where else can you go to read hundreds of candid testimonials or complaints about every aspect of an item.\n",
    "\n",
    "2.1 Consumers Prefer Online Review –\n",
    "\n",
    " ▪ Study after study has shown that consumers are increasingly reliant upon online reviews when making purchasing decisions.\n",
    "\n",
    " ▪ In fact, a recent Nielson study found that 70 percent of global consumers trust online reviews, up 15 percent within a four-year period. Industry experts project this trend to further increase in the coming years.\n",
    "\n",
    " ▪ If consumers love online reviews, what better reason does a merchant need? Sellers are in the business of delivering product that customers will rave about.\n",
    " \n",
    " ▪ Acknowledging the growing importance of online reviews is the first step toward better understanding the market.\n",
    "\n",
    "2.2 Reviews Provide Valuable Market Intelligence-\n",
    "\n",
    " ▪ For Entrepreneurs new to ecommerce, determining which product to sell can be overwhelming. This decision is even difficult for the most experienced sellers. To bring order to this process, many merchants turn to reviewing and tracking reviews.\n",
    "    \n",
    " ▪ Consider, for a moment, Amazon’s full directory of product categories, within a given category, there are several subcategories. At the product level, each item is given “Amazon Best Sellers Rank’ within Subcategories. By analyzing the reviews from product at the top, middle and bottom of these lists, sellers can gain invaluable insights into consumers preference and concerns.\n",
    "\n",
    " ▪ In short, reviews can serve as a digital focus group for any given product. This freely available information can then be used by the merchant to make inventor or strategic placement decision and even to create entirely new product and brands to address limitation in current offering.\n",
    "\n",
    "2.3 Smart Sellers Monitor Reviews-\n",
    "\n",
    " ▪ Reviews play even more important role for third-party merchants.\n",
    "\n",
    " ▪ Understanding the psychology of customer reviews is important for making smart business decision, winning the Buy Box and ultimately thriving online.\n",
    "\n",
    "2.4 Customers Can Vent About Product, Not the Merchant-\n",
    "\n",
    " ▪ Although product can certainly be a representation of the merchant’s brand, it is impossible for a seller to ensure satisfaction for each item sold.\n",
    "\n",
    " ▪ Personal taste and preference, incorrect sizing or unrealistic expectation can dissonance.\n",
    "\n",
    " ▪ A negative comment about the product in the form of a review is typically less impactful to the seller than negative feedback.\n",
    "\n",
    " ▪ By offering two separate forums for people to share their opinions, merchants are able to protect their reputation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658a5a2",
   "metadata": {},
   "source": [
    "# 3 DATA DESCRIPTION –"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fc3b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0fb7d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Reviews_2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a011f7",
   "metadata": {},
   "source": [
    "▪ There is 10 attribute Id, ProductId, UserId, ProfileName, HelpfullnessNumerator, HelpfullnessDenominator, Score, Time, Summary and Text.\n",
    "\n",
    "▪ For further information about the data, we can get the column name, the shape of the data and the dimensions of data available to have more clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f068d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c3ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a153c5",
   "metadata": {},
   "source": [
    "▪ The info () method is useful to get a quick description of the data, in particular the total\n",
    "number of rows, and each attribute’s type and number of non- null values\n",
    "\n",
    "▪ There are 568454 instances in the dataset. Notice that the ProfileName, Summary attribute has 568438 ,5688427 non null values, meaning that 16 ProfileName and 27 Summary missing this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078adff",
   "metadata": {},
   "source": [
    "▪ Let’s look at the other fields. The describe () method shows a summary of the numeric attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a728c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>568454.00000</td>\n",
       "      <td>568454.000000</td>\n",
       "      <td>5.684540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>1.743817</td>\n",
       "      <td>2.22881</td>\n",
       "      <td>4.183199</td>\n",
       "      <td>1.296257e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164098.679298</td>\n",
       "      <td>7.636513</td>\n",
       "      <td>8.28974</td>\n",
       "      <td>1.310436</td>\n",
       "      <td>4.804331e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.393408e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142114.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.271290e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>284227.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.311120e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>426340.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.332720e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>568454.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>923.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.351210e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
       "count  568454.000000         568454.000000            568454.00000   \n",
       "mean   284227.500000              1.743817                 2.22881   \n",
       "std    164098.679298              7.636513                 8.28974   \n",
       "min         1.000000              0.000000                 0.00000   \n",
       "25%    142114.250000              0.000000                 0.00000   \n",
       "50%    284227.500000              0.000000                 1.00000   \n",
       "75%    426340.750000              2.000000                 2.00000   \n",
       "max    568454.000000            866.000000               923.00000   \n",
       "\n",
       "               Score          Time  \n",
       "count  568454.000000  5.684540e+05  \n",
       "mean        4.183199  1.296257e+09  \n",
       "std         1.310436  4.804331e+07  \n",
       "min         1.000000  9.393408e+08  \n",
       "25%         4.000000  1.271290e+09  \n",
       "50%         5.000000  1.311120e+09  \n",
       "75%         5.000000  1.332720e+09  \n",
       "max         5.000000  1.351210e+09  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494317da",
   "metadata": {},
   "source": [
    "▪ The count, mean, min and max rows are self-explanatory. Note that null values are ignored.\n",
    "\n",
    "▪ The std rows shows the standard deviation, which measure how dispersed the values are.\n",
    "\n",
    "▪ The 25 %, 50 % and 75 % rows show the corresponding percentiles; percentiles indicate the value below which a given percentage of observation in a group of observation falls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda21d16",
   "metadata": {},
   "source": [
    "# 4 DATA PRE-PROCESSING STEPS AND INSPIRATION –"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595821f",
   "metadata": {},
   "source": [
    "4.1 Loading The Data –\n",
    " \n",
    "    We have imported all the necessary libraries to perform the EDA, and have imported the dataset using the read_csv () from pandas module. EDA is an approach to analyze the data using visual techniques. It is used to discover trends, patterns, or to check assumptions with the help of statistical summary and graphical representations. \n",
    "\n",
    "4.2 Data Cleaning and Encoding– \n",
    "\n",
    "   • Cleaning up the data frame, by dropping any rows that have missing values.\n",
    "    \n",
    "   • Most Machine Learning algorithm cannot work with missing feature, so that created a function to take care of them. We noticed earlier that There are 568454 instances in the dataset, ProfileName, Summary attribute has 568438 ,5688427 non null values, meaning that 16 ProfileName and 27 Summary missing this feature.\n",
    "\n",
    "   • We can accomplish these easily using Data Frame’s dropna () methods.\n",
    "  \n",
    "   • The Score column is scaled from 1 to 5, and we will remove all Scores equal to 3 because we assume these are neutral and did not provide us any useful information. We then add a new column called “Positivity”, where any score above 3 is encoded as a 1, indicating it was positively rated. Otherwise, it’ll be encoded as a 0, indicating it was negatively rated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35b324f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         0\n",
       "ProductId                  0\n",
       "UserId                     0\n",
       "ProfileName               16\n",
       "HelpfulnessNumerator       0\n",
       "HelpfulnessDenominator     0\n",
       "Score                      0\n",
       "Time                       0\n",
       "Summary                   27\n",
       "Text                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c957d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc1c9cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                        0\n",
       "ProductId                 0\n",
       "UserId                    0\n",
       "ProfileName               0\n",
       "HelpfulnessNumerator      0\n",
       "HelpfulnessDenominator    0\n",
       "Score                     0\n",
       "Time                      0\n",
       "Summary                   0\n",
       "Text                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f8123f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568411, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cf8572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
       "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eeeb4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                         int64\n",
       "ProductId                 object\n",
       "UserId                    object\n",
       "ProfileName               object\n",
       "HelpfulnessNumerator       int64\n",
       "HelpfulnessDenominator     int64\n",
       "Score                      int64\n",
       "Time                       int64\n",
       "Summary                   object\n",
       "Text                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eed1d583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Positivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \\\n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...   \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...   \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "   Positivity  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           0  \n",
       "4           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Score'] != 3]\n",
    "df['Positivity'] = np.where(df['Score']>3,1,0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf2f1a",
   "metadata": {},
   "source": [
    "# 4.3 Splitting The Data into Train and Test –"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ebbbb",
   "metadata": {},
   "source": [
    "▪ Scikit-Learn provide a few functions to split dataset into multiple subsets in various ways. The simplest function is train_test_split, which doesn’t pretty much same thing as the function split_train_test, with a couple of additional features.\n",
    "\n",
    "▪ First there is random_state parameter that allows to set the random generator seed.\n",
    "\n",
    "▪ Second, we can pass it multiple datasets with an identical number of rows, and it will split them on the same indices. \n",
    "\n",
    "▪ Split our data into random training and test subsets using “Text” and “Positivity” columns, and then print out the first entry and the shape of the training set. \n",
    "\n",
    "▪ Looking at X_train, we can see that we have a collection of over 426308 reviews or documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7245aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db6691a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(df['Text'],df['Positivity'],random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78cb863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train first entry: \n",
      "\n",
      " I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n"
     ]
    }
   ],
   "source": [
    "print('x_train first entry: \\n\\n',x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c874a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426308,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4faf81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142103,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0c192ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426308,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1b22d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142103,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69306807",
   "metadata": {},
   "source": [
    "▪ In order to perform machine learning on text documents, we first need to turn these text content into numerical feature vectors that Scikit-Learn can use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a14eb",
   "metadata": {},
   "source": [
    "4.4 Bag-of-Words Model – \n",
    "\n",
    "▪ The simplest and most intuitive way to do so, is the “bags-of-words” representation which ignores structure and simply counts how often each word occurs.\n",
    "\n",
    "▪ CountVectorizer allows us to use the bags-of-words approach, by converting a collection of text documents into a matrix of token counts. \n",
    "\n",
    "▪ We instantiate the CountVectorizer and fit it to our training data, converting our collection of text documents into a matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73e64e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer().fit(x_train)\n",
    "vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a37e3e",
   "metadata": {},
   "source": [
    "4.5 Default Ton figuration Tokenize-\n",
    "\n",
    "▪ This model has many parameters; however, the default values are quite reasonable for our purpose. \n",
    "\n",
    "▪ The default configuration tokenizes the string, by extracting words of at least 2 letters or numbers, separated by word boundaries, it then converts everything to lowercase and builds a vocabulary using these tokens.\n",
    "\n",
    "▪ We can get some of the vocabularies by using the get_feature_names method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3012a508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Library\\mkspecs\\devices\\devika\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '255g',\n",
       " '843mg',\n",
       " 'aftertraste',\n",
       " 'anticarcinogens',\n",
       " 'average',\n",
       " 'b000mrd5jo',\n",
       " 'b001rqemwi',\n",
       " 'b005jd60wk',\n",
       " 'beleive',\n",
       " 'boobs',\n",
       " 'buttersworth',\n",
       " 'cc',\n",
       " 'chuy',\n",
       " 'compresses',\n",
       " 'cramper',\n",
       " 'decap',\n",
       " 'difficulkt',\n",
       " 'dreamy',\n",
       " 'enchanted',\n",
       " 'expedited',\n",
       " 'fists',\n",
       " 'frother',\n",
       " 'gloved',\n",
       " 'gurantees',\n",
       " 'hiking_',\n",
       " 'images',\n",
       " 'intruder',\n",
       " 'kavanagh',\n",
       " 'lawry',\n",
       " 'lowry',\n",
       " 'matured',\n",
       " 'misnomer',\n",
       " 'mythreads',\n",
       " 'numorous',\n",
       " 'osco',\n",
       " 'paupua',\n",
       " 'pittston',\n",
       " 'preshave',\n",
       " 'quart',\n",
       " 'refrigerante',\n",
       " 'ringworm',\n",
       " 'savedge',\n",
       " 'sheer',\n",
       " 'smiths',\n",
       " 'sprklng',\n",
       " 'subtotal',\n",
       " 'taos',\n",
       " 'tiis',\n",
       " 'tubed',\n",
       " 'unsuccessful',\n",
       " 'vomitar',\n",
       " 'wintery',\n",
       " 'zest']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d565e68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106260"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a648dd3",
   "metadata": {},
   "source": [
    "4.6 Transform The Documents In x_train To a Document Term Matrix -\n",
    "\n",
    "▪ Transform gives us the bags-of-word representation of X_train.\n",
    "\n",
    "▪ The result is stored in a SciPy sparse matrix, where each row corresponds to a document, and each column is a word from our training vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e03267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<426308x106260 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 22990341 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_vectorized = vect.transform(x_train)\n",
    "x_train_vectorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f506ab1a",
   "metadata": {},
   "source": [
    "4.7 Train The Logistic Regression Classifier-\n",
    "\n",
    "▪ Train the Logistic Regression classifier based on this feature matrix X_ train_ vectorized, because Logistics Regression works well for high dimensional sparse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bea5e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "633e8180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39dac20",
   "metadata": {},
   "source": [
    "4.8 Predictions Using X_test-\n",
    "\n",
    "▪ Make predictions using X_test, and compute the area under the curve score.\n",
    "\n",
    "▪ determine coefficients weights-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31fe53ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(vect.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1baa3c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3068c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8119806401630989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('AUC: ', roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d28bd3",
   "metadata": {},
   "source": [
    "4.9 Coefficients For Each Feature \n",
    "\n",
    "▪ In order to better understand how our model makes these predictions, we can use the coefficients for each feature (a word) to determine its weight in terms of positivity and negativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5814a8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs: \n",
      "['worst' 'disappointing' 'disappointment' 'awful' 'terrible' 'disgusting'\n",
      " 'threw' 'yuck' 'sorry' 'tasteless']\n",
      "\n",
      "Largest Coefs: \n",
      "['hooked' 'pleasantly' 'pleased' 'skeptical' 'yum' 'beat' 'awesome'\n",
      " 'satisfied' 'yummy' 'delicious']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "print('Smallest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb1162e",
   "metadata": {},
   "source": [
    "4.10 Tf–idf Term Weighting-\n",
    "\n",
    "▪ In a large text corpus, some words will be present very often but will carry very little meaningful information about the actual contents of the document (such as “the”,\n",
    "“a” and “is”). If we were to feed the count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms. \n",
    "\n",
    "▪ Tf-idf allows us to weight terms based on how important they are to a document.\n",
    "\n",
    "▪ Specify min_df = 5, which will remove any words from our vocabulary that appear in fewer than five documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f8ab065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36692"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(min_df = 5).fit(x_train)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9bc61e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8294548648029373\n"
     ]
    }
   ],
   "source": [
    "x_train_vectorized = vect.transform(x_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_vectorized, y_train)\n",
    "predictions = model.predict(vect.transform(x_test))\n",
    "print('AUC: ', roc_auc_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c8982",
   "metadata": {},
   "source": [
    "4.11 Obtain Features with Tf-Idf-\n",
    "\n",
    "▪ Obtain a list of features with the smallest tf-idf that either commonly appeared across all reviews or only appeared rarely in very long reviews and a list of features with the largest tf–idf contains words which appeared frequently in a review, but did not appear commonly across all reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13ab7101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Tfidf: \n",
      "['0373' 'amortized' '0004' '1534' '231' 'amortization' '0377'\n",
      " 'furnishings' '368' 'serine']\n",
      "\n",
      "Largest Tfidf: \n",
      "['carmel' '98' 'yum' 'good' 'filler' 'word' 'love' 'mmm' 'awesome'\n",
      " 'banana']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names())\n",
    "sorted_tfidf_index = x_train_vectorized.max(0).toarray()[0].argsort()\n",
    "print('Smallest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest Tfidf: \\n{}\\n'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041f2a6",
   "metadata": {},
   "source": [
    "# 5. CHOOSING THE ALGORITHM FOR THE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa8f5ef",
   "metadata": {},
   "source": [
    "▪ Logistics Regression works well for high dimensional sparse data. \n",
    "\n",
    "▪ Logistic Regression is commonly used to estimate the probability that an instance belongs to a particular class. If the estimated probability is greater than 50 % then the model predicts that the instance belongs to that class (called the positive class, labeled “1”), or else it predicts that it does not (i.e., it belongs to the negative class, labeled “0”). This makes it binary classifier. \n",
    "\n",
    "▪ In the Score column is scaled from 1 to 5, and we will remove all Scores equal to 3 because we assume these are neutral and did not provide us any useful information. \n",
    "\n",
    "▪ We then add a new column called “Positivity”, where any score above 3 is encoded as a 1, indicating it was positively rated. Otherwise, it’ll be encoded as a 0, indicating it was negatively rated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f2ba23",
   "metadata": {},
   "source": [
    "# 6. ASSUMPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5434ce44",
   "metadata": {},
   "source": [
    "▪ A linear relationship between the dependent and independent variables Not require \n",
    "\n",
    "▪ The error terms (residuals) do not need to be normally distributed. \n",
    "\n",
    "▪ Homoscedasticity is not required. \n",
    "\n",
    "▪ The dependent variable is not measured on an interval or ratio scale. \n",
    "\n",
    "▪ Observations to be independent of each other. In other words, the observations should not come from repeated measurements or matched data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab897c",
   "metadata": {},
   "source": [
    "# 7.MODEL EVALUATION AND TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2c2483",
   "metadata": {},
   "source": [
    ".Import all the necessary libraries\n",
    "\n",
    ".Import the dataset\n",
    "\n",
    ".Dropping any rows that have missing values\n",
    "\n",
    ".Encode The Score column is\n",
    "\n",
    ".Add a new column called “Positivity”\n",
    "\n",
    ".Splitting The Data into Train and Test\n",
    "\n",
    ".Instantiate the CountVectorizer which allows us to use the bags-of-words approach, by converting a collection of text documents into a matrix of token counts.\n",
    "\n",
    ".Use get_feature_names method to get the vocabularies.\n",
    "\n",
    ".Transform the documents in X_train to a document term matrix\n",
    "\n",
    ".Train the Logistic Regression classifier\n",
    "\n",
    ".Use the coefficients for each feature (a word) to determine its weight in terms of positivity and negativity\n",
    "\n",
    ".Instantiate the tf–idf vectorizer to weight terms-based importance\n",
    "\n",
    ".Obtain a list of features with the smallest tf-idf and largest tf–idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e89ad",
   "metadata": {},
   "source": [
    "# 8. INFERENCES FROM THE PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84e69de",
   "metadata": {},
   "source": [
    ". There may be a correlation between the length of a review and the star rating it gives. Longer reviews may tend to have more detailed feedback and possibly higher star ratings.\n",
    "\n",
    ". Certain products may have more negative or positive reviews than others, indicating that there are factors that influence customer satisfaction beyond just the quality of the product itself, such as shipping speed, customer service, or packaging.\n",
    "\n",
    ". Some reviews may be fake or incentivized, either from competitors or from companies themselves trying to artificially inflate their product ratings. Detecting these fake reviews could be important for maintaining the integrity of the review system on Amazon.\n",
    "\n",
    ". There may be differences in review patterns or sentiment based on geographic location, cultural background, or other demographic factors of the reviewers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5979cb4",
   "metadata": {},
   "source": [
    "# 9. FUTURE POSSIBILITIES OF THE PROJECT "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad07956c",
   "metadata": {},
   "source": [
    "▪ More and more people will be use artificial intelligence tools for ecommerce to boost conversions. \n",
    "\n",
    "▪ Customers will believe their experiences could be improved if the pages and links weren’t so small to click on. Another concern for these customers is the lack of information and product reviews available on some online platforms.\n",
    "\n",
    "▪ These areas of improvement will make mobile ecommerce one of the hottest ecommerce future trends that companies could really work on. \n",
    "\n",
    "▪ The introduction of AI and machine learning will here to revolutionize the future of ecommerce. Ecommerce stores will be incorporating machine learning technology on their websites to enhance their customers’ experiences.\n",
    "\n",
    "▪ Machine learning will be starting to play a major role in the ecommerce industry. With this technology businesses will show product recommendations based on customer’s buying behavior and the pages they visit. Moreover, AI and machine learning will help to give customers a visual experience of the product in the form of 3D models, online tours, etc. \n",
    "\n",
    "▪ When it comes to the future of e-business, it’s safe to say that the use of machine learning to enhance online customer experiences will become one of the hottest ecommerce trends, one that ecommerce businesses will greatly benefit from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af377cc9",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d5c30a",
   "metadata": {},
   "source": [
    "The analysis reveals two group of reviewers standing out in helpfulness to the community: First group are those who write long reviews, and second are the ones writing very frequent shorter reviews. For a simple logistic regression electronic review dataset can accuracy close to 0.8 was possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee4735",
   "metadata": {},
   "source": [
    "# 10. REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5d47d",
   "metadata": {},
   "source": [
    "kaggle website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46cb5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
